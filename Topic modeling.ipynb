{
 "metadata": {
  "name": "",
  "signature": "sha256:b3421577e6b8c7ded3683879713cf1cfd827a43a1e63223f698f7364c9528322"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Topic modeling\n",
      "\n",
      "Gregor Czerner\n",
      "\n",
      "E-Mail: g.cz@gmx.de\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ziel dieser Arbeit ist es mittels einer Naive-Bayes Klassifikation auf die bin\u00e4re Unterscheidung unterschiedlicher Kategorien f\u00fcr Texte des Brown Corpus zu trainieren. Ziel ist es einen zuverl\u00e4ssigen Klassifikator zu erhalten, mit dem Texte anhand ihrer Merkmale zu den jeweiligen Kategorien zugeordnet werden k\u00f6nnen. Neben den groben Kategorien 'Information' und 'Unterhaltung', wird im weiteren verlauf auch eine datailliertere Unterscheidung auf Basis bereits exisiteriender Kategorien aus den Brown Corpus unternommen.\n",
      "\n",
      "Zun\u00e4chst wird der Corpus geladen und ein \u00dcberblick \u00fcber die einzelnen Kategorien verschafft. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "from nltk.corpus import brown\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for category in brown.categories():\n",
      "    print category, len(brown.fileids(category))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "adventure 29\n",
        "belles_lettres 75\n",
        "editorial 27\n",
        "fiction 29\n",
        "government 30\n",
        "hobbies 36\n",
        "humor 9\n",
        "learned 80\n",
        "lore 48\n",
        "mystery 24\n",
        "news 44\n",
        "religion 17\n",
        "reviews 17\n",
        "romance 29\n",
        "science_fiction 6\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Der erste Trainingscorpus soll aus zwei Kategorien bestehen **Unterhaltung** und **Information**. Um diese zu erstellen, werden zun\u00e4chst einige urspr\u00fcngliche Kategorien bzw. die entsprechenden Texte in zwei Listen festgehalten (information, unterhaltung). Damit kann eine Liste von Tupeln erstellt werden, die zwischen *unterhaltung* und *information* unterscheiden.\n",
      "Die urspr\u00fcnglichen Kategorien *government, news und editorial* setzen sich zu *Informationen* zusammen und *mystery, romance und science_fiction* zu *Unterhaltung*.\n",
      "Die fileids und Kategorien der Texte werden dann alle unter 'documents' zusammengefasst."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "information = ([(text) for text in brown.fileids('government')] +\n",
      "              [(text) for text in brown.fileids('news')] +\n",
      "              [(text) for text in brown.fileids('editorial')])\n",
      "\n",
      "unterhaltung =([(text) for text in brown.fileids('mystery')] + \n",
      "              [(text) for text in brown.fileids('romance')] + \n",
      "              [(text) for text in brown.fileids('science_fiction')])\n",
      "\n",
      "allfileids = (information+unterhaltung) #wird im weiteren Verlauf ben\u00f6tigt.\n",
      "                 \n",
      "documents = ([(list(brown.words(fileid)), 'information') for fileid in information] +\n",
      "             [(list(brown.words(fileid)), 'unterhaltung') for fileid in unterhaltung])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Anzahl der Texte insg.:', len(documents)\n",
      "print 'Informationstexte:', len(information)\n",
      "print 'Unterhaltungstexte:', len(unterhaltung)\n",
      "\n",
      "print 'Durchschn. Wortzahl Info:', len(brown.words(information))/len(information) #im Schnitt ca. 2300 Worte\n",
      "print 'Durchschn. Wortzahl Unterh:', len(brown.words(unterhaltung))/len(unterhaltung) #im Schnitt ca. 2400 Worte\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Anzahl der Texte insg.: 160\n",
        "Informationstexte: 101\n",
        "Unterhaltungstexte: 59\n",
        "Durchschn. Wortzahl Info: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2299\n",
        "Durchschn. Wortzahl Unterh: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2401\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Insgesamt befinden sich 160 Texte in den beiden Kategorien. 101 werden den Informationstexten und 59 den Unterhaltungstexten zugeordnet. Durchschnittlich liegt die Wortzahl der Texte bei 2300 bzw. 2400.\n",
      "Um im weiteren Verlauf eine zuf\u00e4llige Auswahl der Texte bzw. eine zuf\u00e4llige Zuordnung zu Trainigs- und Testset zu garantieren, wird die Textreihenfolge randomisiert."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import random\n",
      "random.shuffle(documents)\n",
      "#print documents[0] "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Als n\u00e4chstes wird der sogenannte *feature extractor* f\u00fcr die Dokumente definiert, die der Klassifikator zur Identifikation der Eigenschaften der Texte ben\u00f6tigt. Diese bestehen in diesem Fall aus den 1000 h\u00e4ufigsten W\u00f6rtern \u00fcber alle Texte hinweg. Um m\u00f6glichst aussagekr\u00e4ftige W\u00f6rter in die Liste aufzunehmen, wurden die Texte hierzu um sogenannte Stoppw\u00f6rter wie *and, or etc.* bereinigt und lediglich alphanumerische Zeichen zugelassen. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import stopwords #importieren der stopwords vom nltk.corpus\n",
      "stopwords = stopwords.words('english') \n",
      "stopwords.append('also')\n",
      "\n",
      "all_words = nltk.FreqDist(w for w in brown.words(allfileids) \n",
      "                          if w.isalpha() \n",
      "                          and w not in stopwords)\n",
      "\n",
      "\n",
      "word_list = all_words.keys()[:1000]\n",
      "\n",
      "# Etwas flexiblere Version verglichen mit der in\n",
      "# NLTK Example 6.4\n",
      "# Erlaubt Wortlisten als Argument:\n",
      "def document_features(document, word_list):\n",
      "    document_words = set(document)\n",
      "    features = {}\n",
      "    for word in word_list:\n",
      "        features['contains(%s)' % word] = (word in\n",
      "                                           document_words)\n",
      "    return features\n",
      "\n",
      "##Wieviele W\u00f6rter?\n",
      "print len(word_list)\n",
      "print len(all_words)\n",
      "#word_list[:100]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1000\n",
        "23814\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Nun kann ein Test- und ein Trainingsset erstellt werden. Das Testset dient um die eben definierte Methode auf ihre Zuverl\u00e4ssigkeit zu testen. Das Trainigsset dient zum Trainieren des Klassifizierers, der mit den belabelten Texten und der 1000 W\u00f6rtern versucht Texte den jeweiligen Labels zuzuordnen. Hierf\u00fcr wurden dem Trainigsset etwa dreiviertel der Texte zuf\u00e4llig zugeordnet und ein Viertel zum sp\u00e4teren \u00dcberpr\u00fcfen zur\u00fcckgehalten. \n",
      "\n",
      "Es erscheint insbesondere bei der Einordnung von Texten in einzelne Kategorien sinnvoll nach den h\u00e4ufigsten W\u00f6rtern zu unterscheiden, da sich die sprachliche Dichte in Informations- und Unterhaltungstexten deutlich unterscheiden sollte. So wird vermutet, dass insbesondere durch die sehr themenspezifische W\u00f6rter in den Informationstexten eine zuverl\u00e4ssige Unterscheidung m\u00f6glich sein sollte."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Format: Liste von Tuplen (Eigenschafts-Diktion\u00e4r, Label) \n",
      "featuresets = [(document_features(d, word_list), c)\n",
      "               for (d, c) in documents]\n",
      "\n",
      "# Ein Test-Set zur\u00fcckhalten f\u00fcr sp\u00e4tere\n",
      "# \u00dcberpr\u00fcfung des Klassifizierers!\n",
      "train_set, test_set = featuresets[:120], featuresets[120:] #75% Training\n",
      "\n",
      "#train_set[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Das Modell wird nun im Trainigsset trainiert und anschlie\u00dfend am Testset \u00fcberpr\u00fcft. Mit einer Genauigkeit von 95% sch\u00e4tzt er das richtige Labels zu. Aufgrund der \u00e4u\u00dferst geringen Fallzahl wird der Test mehrfach mittels crossvalidation wiederholt. Bei geringen Fallzahlen k\u00f6nnen trotz zuf\u00e4lliger Zuordnung der Texte zu Trainigs- und Testset die Ergebnisse je nach Zuordnung stark variieren. Hier ist es sinnvoll die Zuverl\u00e4ssigkeit genauer zu testen und zu betrachten wie konstant die Ergebnisse sind.\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifier = nltk.NaiveBayesClassifier.train(train_set)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##Beispiel 55. Dokument:\n",
      "print 'Original:', documents[55][1]\n",
      "print 'Sch\u00e4tzung:', classifier.classify(document_features(documents[55][0],\n",
      "                                      word_list))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Original: unterhaltung\n",
        "Sch\u00e4tzung: unterhaltung\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Accuracy', nltk.classify.accuracy(classifier, test_set) \n",
      "classifier.show_most_informative_features(20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.95\n",
        "Most Informative Features\n",
        "         contains(Maybe) = True           unterh : inform =      9.6 : 1.0\n",
        "         contains(dirty) = True           unterh : inform =      8.7 : 1.0\n",
        "      contains(opposite) = True           unterh : inform =      7.7 : 1.0\n",
        "    contains(leadership) = True           inform : unterh =      6.7 : 1.0\n",
        "      contains(imagined) = True           unterh : inform =      6.7 : 1.0\n",
        "         contains(chair) = True           unterh : inform =      6.5 : 1.0\n",
        "          contains(door) = True           unterh : inform =      6.3 : 1.0\n",
        "        contains(blonde) = True           unterh : inform =      5.7 : 1.0\n",
        "         contains(mouth) = True           unterh : inform =      5.7 : 1.0\n",
        "        contains(pulled) = True           unterh : inform =      5.5 : 1.0\n",
        "        contains(extent) = True           inform : unterh =      5.4 : 1.0\n",
        "          contains(task) = True           inform : unterh =      5.4 : 1.0\n",
        "       contains(College) = True           inform : unterh =      5.4 : 1.0\n",
        "       contains(climbed) = True           unterh : inform =      5.2 : 1.0\n",
        "        contains(turned) = False          inform : unterh =      5.2 : 1.0\n",
        "     contains(operation) = True           inform : unterh =      5.1 : 1.0\n",
        "        contains(former) = True           inform : unterh =      5.1 : 1.0\n",
        "          contains(role) = True           inform : unterh =      5.0 : 1.0\n",
        "        contains(minute) = True           unterh : inform =      5.0 : 1.0\n",
        "           contains(May) = True           inform : unterh =      4.8 : 1.0\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gold = [tag for text, tag in documents]\n",
      "test = [classifier.classify(document_features(text, word_list)) \n",
      "        for text, tag in documents]\n",
      "\n",
      "cm = nltk.ConfusionMatrix(gold, test)\n",
      "\n",
      "print(cm.pretty_format(sort_by_count=True, show_percents=True, truncate=9))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             |             u |\n",
        "             |      i      n |\n",
        "             |      n      t |\n",
        "             |      f      e |\n",
        "             |      o      r |\n",
        "             |      r      h |\n",
        "             |      m      a |\n",
        "             |      a      l |\n",
        "             |      t      t |\n",
        "             |      i      u |\n",
        "             |      o      n |\n",
        "             |      n      g |\n",
        "-------------+---------------+\n",
        " information | <61.9%>  1.2% |\n",
        "unterhaltung |   0.6% <36.2%>|\n",
        "-------------+---------------+\n",
        "(row = reference; col = test)\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 340
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def crossvalidation(sets, runs):\n",
      "    for run in range(runs):\n",
      "        random.shuffle(documents)\n",
      "        featuresets = [(document_features(d, word_list), c)\n",
      "               for (d, c) in documents]\n",
      "        train_set, test_set = featuresets[:sets], featuresets[sets:]\n",
      "        classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
      "        print 'Accuracy', nltk.classify.accuracy(classifier, test_set) \n",
      "\n",
      "print crossvalidation(120, 5)\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.95\n",
        "Accuracy"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.925\n",
        "Accuracy"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.875\n",
        "Accuracy"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.975\n",
        "Accuracy"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.975\n",
        "None\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Bei Wiederholung und erneuter Randomisierung variieren die Ergebnisse stark. Was vermutlich auf die geringe Fallzahl zur\u00fcckzuf\u00fchren ist und an der Zuverl\u00e4ssigkeit des Sch\u00e4tzers zweifeln l\u00e4sst. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Bei Betrachtung der informativsten Eigenschaften f\u00e4llt auf, dass es sich in den meisten F\u00e4llen um Adjektive handelt, z.B. ist *Dirty* 9 mal wahrscheinlicher in Unterhaltungstexten als in Informationstexten. Aufgrund dieser Tatsache erscheint es sinnvoll eine weitere Analyse lediglich auf Basis der Adjektive in den Texten vorzunehmen und diese als Eigenschaften zu unterscheiden.\n",
      "Hierf\u00fcr werden die zuvor unternommenen Schritte wiederholt, mit den Unterschied, dass die Wortliste auf vordefinierte Adjektive eingeschr\u00e4nkt wird, die im brown Corpus klar unterschieden werden.\n",
      "\n",
      "Aus 3615 Adjektiven werden wieder die 1000 h\u00e4ufigsten gew\u00e4hlt."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      " tagged = [w for (w, tag) in brown.tagged_words(fileids=allfileids) if tag == 'JJ' ]\n",
      "# tag_fd = nltk.FreqDist(tag for (word, tag) in tagged_words)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_words = nltk.FreqDist(w for w in tagged) \n",
      "\n",
      "word_list = all_words.keys()[:1000]\n",
      "\n",
      "# Etwas flexiblere Version verglichen mit der in\n",
      "# NLTK Example 6.4\n",
      "# Erlaubt Wortlisten als Argument:\n",
      "def document_features(document, word_list):\n",
      "    document_words = set(document)\n",
      "    features = {}\n",
      "    for word in word_list:\n",
      "        features['contains(%s)' % word] = (word in\n",
      "                                           document_words)\n",
      "    return features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(word_list)\n",
      "print len(all_words)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1000\n",
        "3615\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print crossvalidation(120, 5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.9\n",
        "Accuracy"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.925\n",
        "Accuracy"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.925\n",
        "Accuracy"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.975\n",
        "Accuracy"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.925\n",
        "None\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In diesem Fall scheint der Sch\u00e4tzer zuverl\u00e4ssiger zu sein. Die Schwankungen der richtigen Zurodnung der Texte sind in diesen f\u00fcnf L\u00e4ufen etwas geringer als zuvor, was auf eine pr\u00e4zisere Unterscheidung durch die blo\u00dfe Betrachtung der Adjektive zur\u00fcckgef\u00fchrt werden kann."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Nun wird noch einmal ein Klassifikator erstellt, der anstelle der zwei groben Kategorien *Information* und *Unterhaltung* nun zwischen den urspr\u00fcnglichen Kategorien unterscheidet, die diese gebildet haben.\n",
      "Aufgrund der geringen Fallzahl und der bin\u00e4ren Unterscheidung des Bayes-Sch\u00e4tzers, wie er hier verwendet wird, f\u00e4llt das Ergebnis in diesem Fall deutlich schlechter aus. Lediglich 55% der Texte werden richtig zugeordnet. Auch in diesem Fall wurde auf die Adjektive zur\u00fcckgegriffen, da sie zuvor ein zuverl\u00e4ssigeres Ergebnis geliefert haben, als die blo\u00dfe H\u00e4ufigkeitsunterscheidung aller W\u00f6rter.\n",
      "\n",
      "\n",
      "Auch die Ergebnisse der Confusions-Matrix sind nicht \u00fcberraschend. Vor allem zwischen den Kategorien, die zuvor in der gr\u00f6beren Unterscheidung zwischen 'Unterhaltung' und 'Informationen' zu einer Kategorie geh\u00f6rt haben, unterscheidet der Sch\u00e4tzer in einigen F\u00e4llen nicht richtig.\n",
      "\n",
      "Vermutlich sollte hier auf Klassifizierer zur\u00fcckgegriffen werden, die eine bessere Unterscheidung zwischen multiplen Klassen zul\u00e4sst."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "old_cat = ['mystery', 'romance', 'science_fiction', 'government', 'news', 'editorial']\n",
      "\n",
      "documents = [(list(brown.words(fileid)), category)\n",
      "                for category in old_cat\n",
      "                for fileid in brown.fileids(category)]\n",
      "random.shuffle(documents)\n",
      "\n",
      "def document_features(document, word_list):\n",
      "    document_words = set(document)\n",
      "    features = {}\n",
      "    for word in word_list:\n",
      "        features['contains(%s)' % word] = (word in\n",
      "                                           document_words)\n",
      "    return features\n",
      "\n",
      "#print documents[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "random.shuffle(documents)\n",
      "featuresets = [(document_features(d, word_list), c)\n",
      "for (d, c) in documents]\n",
      "train_set, test_set = featuresets[:120], featuresets[120:]\n",
      "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
      "\n",
      "\n",
      "print 'Accuracy', nltk.classify.accuracy(classifier, test_set) \n",
      "classifier.show_most_informative_features(20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.55\n",
        "Most Informative Features\n",
        "          contains(left) = True           myster : govern =     13.4 : 1.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         contains(human) = True           scienc : news   =     12.4 : 1.0\n",
        "          contains(left) = False          govern : myster =     10.6 : 1.0\n",
        "     contains(Communist) = True           editor : romanc =      9.4 : 1.0\n",
        "          contains(dead) = True           myster : govern =      9.1 : 1.0\n",
        "        contains(inside) = True           myster : govern =      9.1 : 1.0\n",
        "      contains(enormous) = True           scienc : news   =      8.9 : 1.0\n",
        "           contains(lay) = True           myster : editor =      7.7 : 1.0\n",
        "          contains(then) = False          govern : romanc =      7.3 : 1.0\n",
        "     contains(objective) = True           govern : news   =      7.3 : 1.0\n",
        "         contains(worth) = True           scienc : romanc =      7.2 : 1.0\n",
        "   contains(responsible) = True           scienc : romanc =      7.2 : 1.0\n",
        "         contains(brown) = True           romanc : news   =      7.0 : 1.0\n",
        "          contains(Then) = True           scienc : govern =      6.6 : 1.0\n",
        "       contains(content) = True           scienc : govern =      6.1 : 1.0\n",
        "          contains(just) = False          govern : romanc =      5.9 : 1.0\n",
        "       contains(maximum) = True           govern : romanc =      5.9 : 1.0\n",
        "          contains(free) = True           editor : romanc =      5.7 : 1.0\n",
        "        contains(likely) = True           editor : romanc =      5.7 : 1.0\n",
        "      contains(opposite) = True           myster : news   =      5.6 : 1.0\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gold = [tag for text, tag in documents]\n",
      "test = [classifier.classify(document_features(text, word_list)) \n",
      "        for text, tag in documents]\n",
      "\n",
      "cm = nltk.ConfusionMatrix(gold, test)\n",
      "\n",
      "print(cm.pretty_format(sort_by_count=True, show_percents=True, truncate=9))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                |                                         s |\n",
        "                |                                         c |\n",
        "                |                                         i |\n",
        "                |                                         e |\n",
        "                |                                         n |\n",
        "                |             g                           c |\n",
        "                |             o             e             e |\n",
        "                |             v             d             _ |\n",
        "                |             e      r      i      m      f |\n",
        "                |             r      o      t      y      i |\n",
        "                |             n      m      o      s      c |\n",
        "                |      n      m      a      r      t      t |\n",
        "                |      e      e      n      i      e      i |\n",
        "                |      w      n      c      a      r      o |\n",
        "                |      s      t      e      l      y      n |\n",
        "----------------+-------------------------------------------+\n",
        "           news | <25.0%>  1.2%   0.6%   0.6%      .      . |\n",
        "     government |   2.5% <16.2%>     .      .      .      . |\n",
        "        romance |   0.6%      . <17.5%>     .      .      . |\n",
        "      editorial |   2.5%      .      . <14.4%>     .      . |\n",
        "        mystery |   1.9%      .   1.9%      . <11.2%>     . |\n",
        "science_fiction |   1.2%      .   1.2%      .   0.6%  <0.6%>|\n",
        "----------------+-------------------------------------------+\n",
        "(row = reference; col = test)\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print crossvalidation(110, 5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.52\n",
        "Accuracy"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.52\n",
        "Accuracy"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.54\n",
        "Accuracy"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.44\n",
        "Accuracy"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.5\n",
        "None\n"
       ]
      }
     ],
     "prompt_number": 349
    }
   ],
   "metadata": {}
  }
 ]
}